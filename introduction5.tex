
世界中の情報をインターネットを通して集め、有価値化するという試みは、知能における一つの目標であり、検索エンジンによって部分的には実現されている。
しかし、センサーデータといった連続量については未だ不十分であり、Internet of Things (IoT) という産業上のスローガンとして多くの企業が取り組んでいる。
強化学習の文脈において、現実世界は部分観測環境であるため、IoT は観測を増やす作用を担うことで行動の精度を高め、エージェントの累積報酬を高める効果がある。
そのため、IoT は自動株取引、自動運転、スマートグリッド、ECサイトの需要予測など多くの産業上の応用が期待されている。
一方、昨今の IoT はインセンティブ設計が不十分であり、本当に重要なデータが十分に集まらないという課題がある。
これはデータ提供者によって無償でデータを公開する効用が、秘密にした場合の効用を下回るためである。
しかし、近年、ビットコインなどブロックチェーンの仕組みによってマイクロペイメントが可能になり、
それぞれのデータ提供者に細かい単位の報酬を与えることが可能になっている。
報酬系を司る Blockchain と、報酬を最大化する Deep Reinforcement Learning が統合されれば、単一のコンピュータの中での処理だけでなく、
世界規模で爆発的なセンサーデータ活用が起こることが予想される。
本研究のモチベーションは、統合のための最初のアプローチとして、金銭的報酬の最適配分を、マルチエージェント強化学習(MARL)のインスタンスであるとみなし、 ニューラルネットワークを用いたアプローチによって解くことである。

本研究では、エージェント同士がデータの取引や活用を行う状況を、
エージェントの環境に対する観測や行動が間接的に行われる状況によりモデル化する。
こうした状況は、通常のMARLに加え、行動はできるが環境を直接観測できないエージェント（アクチュエーター）、
観測は行えるが、環境に直接影響を及ぼせないため他のエージェントに情報を伝えるエージェント（センサー）、
環境を直接観測も行動もできず、他のエージェントを通してのコミュニケーションのみを行うエージェント（メディエーター）
の存在を許容する。I
アクチュエーターは、環境に直接作用することで報酬を直接受け取り、メディエーターやセンサーに配分することが求められる。
本研究の目的は、環境にそれぞれの役割を持ったエージェントが多数存在した場合に、
これらのエージェントのコミュニケーションや取引を制御することにより、環境から得られる累積報酬の総和を最大化することである。
CommNet はこうした問題を扱っており、コミュニケーションの内容をバックプロパゲーションによって学習している。
一方でこれらの既存研究はエージェント同士に与えられる報酬がすべて同一であると仮定しており、
買い手と売り手が明確に存在し、エージェント同士が取引しあう状況は仮定していない。
%そのため、通貨のような報酬を考えた場合に CommNet は適用できない。
%IoT においてセンサーデータを提供するエージェントはセンサー・エージェントに該当し、
%センサーデータを利用するエージェントはアクチュエーター・エージェントに該当する。

このようにエージェント間の報酬が異なる問題に対して CommNet のような MARL の手法を素朴に適用すると、十分な累積報酬が得られないことが知られている。
これは中央集権的にエージェントを管理する主体が存在しないことで、
相手のエージェントを裏切る方が協力するよりも効用が高くなることに起因する。
具体的に、情報の書い手となるエージェントにとっては、報酬を全く支払わない方が効用が高く、
売り手となるエージェントにとっては、全く処理を行わずにノイズを流すことが効用が高くなる。
結果的に、エージェント同士のコミュニケーションはノイズの海になり、環境からの報酬が最小化するという帰結が得られる。
こうした現象は社会的ジレンマと呼ばれ、中央集権的なエージェントが不在である分散的な状況において、MARL を行う上での妨げとなっている。

本研究では、オークション理論の一つである envy-free auction を利用することで、
設計者が直接手を下さなくても、エージェントが正直に情報の適正価格を申告するようにする。
envy-free auction は、書籍や音楽などの複製可能な財に対するオークション手法である digital goods auction の中で最も基本的なものの一つである。
買い手は売り手の情報に対して入札を行い、売り手は入札された複数の価格の中から自身の利益を最大化する価格を決定する。
情報は最適価格以上の bidding price を提示した買い手のみに行きわたるようにする。
これにより、中央集権的に全体を管理するエージェントが存在しなくても、それぞれのエージェントの行動を通して
エージェントの最適化価格を正直に申告するようにするような報酬設計が行われる。
複数の利己的なエージェント効用を調整することで設計者の目的を達成する方法は経済学では一般的であるため、
本研究は Deep Learning と経済学を融合した研究である。

本研究では、CommNet と同様にエージェント間のコミュニケーションをバックプロパゲーションによって最適化するが、
これははエージェントを一つの非線形な応答をするニューロンであるとみなすことと等価である。
逆説的に、すべてのニューロンを一つのエージェントとみなしたモデルを構築できる。
そこで、本研究では提案手法をNeuron as an Agent (NaaA) と呼ぶ。
NaaA が想定するセンサーエージェント、中間エージェント、アクチュエーターエージェントはそれぞれ、
ニューラルネットワークの入力層、中間層、出力層に対応する。
NaaA はニューラルネットワークをマルチエージェントシステムであるとみなし、Q-learning を用いて bidding price を決定する。
提案手法では、NaaA の枠組みによりニューラルネットワークが最大化する対象が、
自身を含む場合とそうでない場合に買い手が得るリターンの差である counterfactual return に等しくなることを示す。

本論文は以下のように構成される。
まず、NaaA の枠組み及び問題設定について述べ、オークション理論を用いた提案手法について述べる。
次に、二つのアプリケーションを紹介する。一つは VizDoom を拡張したマルチエージェント環境であり、
もう一つはニューラルネットワークのトポロジーの最適化である。
そして関連研究について述べ、応用例について議論し、本研究の結論を述べる。
%一つのエージェントに対して複数の買い手となるエージェントを存在し、

%オークションは経済学における逆ゲーム理論に位置づけられるもので、
%エージェント間の報酬関数を非線形に行うことで帰結として得られる目的を達成するものである。
%これは国家における税金をどう決めるのかや、安定のマッチングを求める問題に応用されており、ノーベル経済学賞を受賞した分野である。

%Deep Reinforcement Learning 
%Communication is important function of animals, it orchestrates swarm more than individuals.
%自然は階層構造をしている。
%フォワード/バックプロパゲーションによってニューロン間で行われる情報のやり取りは、エージェント（生物や機械）間のコミュニケーションでも行われる。
%コミュニケーションは知能において重要な活動の一つであり、部分観測環境においてエージェント間の情報共有を行う手段として有用である。
%%エージェント間のコミュニケーションは、環境が完全観測でなく、単一のエージェントが観測できる環境が限られていたり、
%%行動に限界があったりする場合に、複数エージェントを協力させてより大きな問題を解くために有用である。
%たとえば、生物の多くは目の前しか見ることができないが、もう一人環境に生物がいれば後ろの空間を観測することができ、敵の存在を把握することができる。
%そこで、本研究では、motivating example として次の問いを扱う。

%既存の Deep Reinforcement Learning では、エージェントが環境への観測と行動の両方を直接的に行う状況を仮定しているが、
%で構成されるとき、
%これらを協調動作させることにより、環境から獲得する報酬を最大化したい。
%現実世界におけるサプライチェーン（原材料の採掘から加工、自動車の製造まで）にも類似の構造を見出すことができる。

センサーエージェントがメインのエージェントに最適なコミュニケーションを行うことにより、
エージェントが環境から獲得する報酬を最大化したい。
もし、コミュニケーションが行れなければ、

このような問題は、企業情報の提供者と投資運用業、路面状況提供者と自動車メーカーなど、
情報提供者と企業のようなケースを考えた場合に適用できる適用範囲の広い課題である。

こうしたマルチエージェント環境であると呼ばれ、Q学習をはじめとする強化学習を使って解かれる。
コミュニケーションの研究\cite{}はすべてのエージェントが同一報酬を最大化する協力的状況を仮定しているが、
エージェントが協力的ではなく利己的であると仮定した場合に問題が生じる。
なぜなら、エージェントは利益の獲得のために他のエージェントに対して虚偽の情報を報告したり、
他のエージェントは


既存研究はすべてのエージェントが同一の報酬をシェアするような協力的状況を仮定しているが、
通貨のように供給量が一定である報酬を配分する瞬間に問題が生じる。


エージェント, 生物に含まれるニューラルネットワークは、ニューロン同士の通信によって柔軟な関数近似を実現している。
フォワード/バックプロパゲーションは、突き詰めれば二つのニューロンの間の連続量のコミュニケーションである。
このような細部の構造が、全体としてニューラルネットワークを構成する。
単一のエージェントに限らず、複数のエージェントがコミュニケーションを行うことで、単一のエージェントを上回る性能を得ることができることがある。
CommNet などの

この世界は階層的な構造をしている。

コミュニケーションは知能において重要な活動の一つであり、部分観測環境においてエージェント間の情報共有を行う手段として有用である。
ディープラーニングのモデルについても、離散量としてのもの\cite{}、連続量として行うもの\cite{}があり、それぞれ一定の成果を上げている。

しかし、既存研究はすべてのエージェントが同一の報酬をシェアするような協力的状況を仮定しているが、
通貨のように供給量が一定である通貨を想定した瞬間に問題が生じる。
実際には一部のエージェントは行動をしなくても報酬を受け取るというフリーライダー問題を誘発する。

異なる報酬を持つ利己的なエージェントであると考えた場合には成立しない。

そこで本研究では、次のリサーチクエスチョンを扱う。

「」

% Motivating Example
This paper addresses multi-agent reinforcement learning (MARL) in a partially-observed environment.  
In a partially-observed environment such as, agents can improve their performance with communication.
Suppose the agent playing 



%・

% MARL & エージェント間の通信 & POMDP & selfish
%囚人のジレンマに代表されるような社会的ジレンマが発生するためである。
%社会的ジレンマとは、それぞれのエージェントにとっての局所最適解であるナッシュ均衡が、 全体最適であるパレート最適を達成しない現象を指す。
%たとえば、自動株取引では将来に対する公になっていない情報を持っている方が、他の参加者に先だった先行投資を行えるので儲けが大きい。

