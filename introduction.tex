\section{Introduction}

% ・多分一回 MTG した方がいい（ストーリーの作り方、トピックセンテンス）
% ・有用な観測に対してインセンティブを与える
% ・高次のニューロンも、見方によっては下位のニューロンの信号を観測するメタセンサーであると考えられる 
% このあたりはまだストーリー作りできていません。

マルチエージェントによる強化学習が現実の課題に対して有効である理由は、興味深いことに表現学習の原理と一致する：有用な表現は予測性能を向上させる。
現実にある問題の多くは、DQN が前提としているマルコフ決定過程(MDP)ではなく部分的観測マルコフ決定過程(POMDP)である\citep[p.258]{sutton1998reinforcement}。
POMDP において真の状態は完全には不可視であり、良質な観測結果が良質な行動に結びつくため、有限のリソースを使って何を観測するかの設計が必要である。
必然的に、観測に用いられるエージェントが多いほど、将来的に獲得できる報酬も高くなる。
本論文は、観測という行動においてエージェントとユニットは等価であるということを主張する。
%また、複数のモデルを組み合わせることによって精度が高まるアンサンブル法としての側面が存在する。
%有用な状態表現が精度の向上に寄与するためである。

%======OK=========

本研究のゴールは、すべてのユニットが自律的に動作すると仮定した場合に、システム全体が獲得する累積報酬を最大化することである。
そのために、NaaA は微分可能(differentiable)な関数で構成されるニューラルネットワークを、報酬系の概念を用いて拡張する。
NaaA の特徴は、中央集権的なコントローラを持たない点である。
そのため、環境に存在する複数のエージェントが自律的に動作する。

報酬の分配のためにオークション理論を用いて、ジレンマ問題を解決した上で、
レイヤーの入札価格が、ユニットが存在する場合と存在しない場合の差である counterfactual reward \citep{agogino2006quicr} に等しくなることを示す。
以下では報酬分配のフレームワークである profit maximization について述べ、
Valuation Net について説明を行う。

NaaA は、神経細胞の持つエネルギー消費のメカニズムをモデリングする。
神経回路に含まれるニューロンは一つの細胞であるため、エネルギーを消費する。
通常の細胞と同様に酸素や ATP がエネルギー源となり、これらはニューロンと接続した、アストロサイトから供給される。
アストロサイトは脳の構造を支えるグリア細胞の一種であり、血管からニューロンへの栄養供給を行う。
エネルギー量は有限であるため、不要なニューロンはアポトーシスによって死滅する。
アポトーシスは NGF (nerve growth factor), BDNF (brain derived neurofactor) などの神経栄養因子(neurotorophin; NTF)によって制御されるため、より多くの NTF を獲得できたニューロンが生存する。
各神経細胞を独立した生物として捉える見方はニューラルダーウィズム\citep{edelman1987neural}と呼ばれる。

これまでのニューラルネットワークの目的は、予測誤差 $e$ の最小化にあった。
そのため、各ユニットはバックプロパゲーションによって出力 $y$ による微分 $\partial e / \partial y$ を計算し、
$e$ が小さくなる方向に $y$ の大きさを制御していた。
NaaA において、ユニットの目的は大域的誤差の最小化ではなく、ユニット自身の期待リターンの最大化である。

実験では、標準的な強化学習のタスクによる数値実験を用いて NaaA が POMDP の問題の精度を高めることを示す。
具体的に、Atari および VisDoom における環境を用いて、既存研究が DQN や A3C を上回ることを示す。
