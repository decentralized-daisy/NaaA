\section{Conclusion and Future Works}
This paper proposed NaaA, a reinforcement learning framework that treats each unit on a neural network as an agent.
First, we pointed out there are dilemma problems if we naively optimize NaaA. We
proposed an optimization method with auction.
Consequently, an action by which units evaluate the counterfactual return of other units is obtained as a Nash equilibrium.
Furthermore, we proposed $Q$-learning based algorithm, adaptive dropconnect, to optimize the neural network topology dynamically with evaluation of counterfactual return.
For the evaluation, we performed experiments based on single-agent and multi-agent platforms, demonstrating that our experimentally obtained results improve existing methods.

As a direction of future research, we use on-policy methods to perform adaptive dropconnect, and
consider applications combining genetic algorithms.
