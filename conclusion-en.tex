%\section{Conclusion and Future Works}
\section{Concluding Remarks and Future Work}
This paper proposed a NaaA model to address communication in MARL without a TTP based on two key ideas: inter-agent reward distribution and auction theory.
Existing MARL communication methods have assumed the existence of a TTP, and hence could not be applied in peer--to--peer environments.
The inter-agent reward distribution, making agents redistribute the rewards they received from the internal/external environment, was reviewed first.
When an envy-free auction was introduced using auction theory, it was shown that agents would evaluate the counterfactual returns of other agents.
The experimental results demonstrated that NaaA outperformed a baseline method and a CommNet-based method.

Furthermore, a $Q$-learning based algorithm, termed Adaptive DropConnect, was proposed to dynamically optimize neural network topology with counterfactual return evaluation as a further application.
To evaluate this application, experiments were performed based on a single-agent platform, demonstrating that the proposed method produced improved experimental results relative to existing methods.

% TODO: åãëıÇµÇΩèÍçáÇÃëŒçÙÇÕÇ«Ç±Ç©Ç…èëÇ¢ÇΩï˚Ç™Ç¢Ç¢Ç©Ç‡ÇµÇÍÇ»Ç¢

Future research may also be directed toward considering the connection between NaaA and neuroscience or neuroevolution.
Edeleman propounded the concept of neural Darwinism \citep{edelman1987neural}, in which group selection occurs in the brain.
Inter-agent rewards, which were assumed in this paper, correspond to NTFs
and could be used as a fitness function in genetic algorithms for neuroevolution such as hyperparameter tuning.

As NaaA can be applied in peer-to-peer environments, 
the implementation of NaaA in blockchain \citep{swan2015blockchain} is under consideration.
This implementation would extend the areas where deep reinforcement learning could be applied.
Bitcoin \citep{nakamoto2008bitcoin} could be used for inter-agent reward distribution, and the auction mechanism could be implemented by smart contracts \citep{buterin2014next}.
Using the NaaA reward design, it is hoped that the world may be united, allowing people to share their own representations on a global scale.

%We can use bitcoin \cite{nakamoto2008bitcoin} and smart contract \cite{}a 

%Besides, we proposed Adaptive DropConnect as an further application on a single neural network.
%This paper proposed NaaA, a reinforcement learning framework that treats each unit on a neural network as an agent.
%First, we pointed out there are dilemma problems if we naively optimize NaaA. 
%We proposed an optimization method with auction.
%Consequently, an action by which units evaluate the counterfactual return of other units is obtained as a Nash equilibrium.
%Furthermore, we proposed $Q$-learning based algorithm, adaptive dropconnect, to optimize the neural network topology dynamically with evaluation of counterfactual return.
%For the evaluation, we performed experiments based on single-agent and multi-agent platforms, demonstrating that our experimentally obtained results improve existing methods.

%As a direction of future research, we use on-policy methods to perform adaptive dropconnect, and
%consider applications combining genetic algorithms.
