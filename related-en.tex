\section{Related Works}
% TODO: マルチエージェントの分配についての話を書く

% 既存研究ではどういうアプローチでこの問題を扱っている？
% MARL の研究を基本的には書いていく

% 具体的な内容: CommNet, Forester
% QUICR, COMA
% Adaptive DropConnect

Existing multi-agent reinforcement learning (MARL) communication methods have relied on a trusted third party (TTP) to distribute incentive to agents, leaving them inapplicable in peer-to-peer environments.
R/DIAL \citep{foerster2016learning} is a communication method for deep reinforcement learning, which train the optimal communication among the agent with Q-learning. It focuses on that paradigm of centralized planning.
CommNet \citep{sukhbaatar2016learning}, which exploits the characteristics of a unit that is agnostic to the topology of other units, employs backpropagation to train multi-agent communication.
Instead of reward $R(a_t)$ of an agent $i$ for actions at $t$ $a_t$, 
QUICR-learning \citep{agogino2006quicr} maximizes counterfactual reward $R(a_t) - R(a_t - a_{it})$, the difference in the case of the agent $i$ takes an action $a_{it}$ ($a_t$) and not ($a_t-a_{it}$).
COMA \citep{foerster2017counterfactual} also maximizes counterfactual rewards in an actor--critic setting.
CommNet, QUICR and COMA have a centralized environment for distributing rewards through a TTP.
%Hence, these methods above cannot be applied into peer-to-peer setting.
In contrast, NaaA does not rely on a TTP, and hence, each agent calculates its reward.

While inter-agent reward distribution has not been considered in the context of communication,
trading agents have been considered in other contexts.
Trading agent competition (TACs), competitions for trading agent design, have been held in various locations regarding topics such as smart grids \citep{ketter2013power}, wholesale \citep{kuate2013intelligent}, and supply chains \citep{pardoe2009autonomous}, 
yielding innumerable trading algorithms such as Tesauro's bidding algorithm \citep{tesauro2002strategic} and TacTex'13 \citep{urieli2014tactex}.
Since several competitions employed an auction as optimal price determination mechanism \citep{wellman2001designing,stone2003decision},
using auctions to determine optimal prices is now a natural approach.
Unfortunately, these existing methods cannot be applied to the present situation.
First, their agents did not communicate because the typical purpose of a TAC is to create market competition between agents in a zero-sum game. 
Secondly, the traded goods are not digital goods but instead goods in limited supply, such as power and tariffs.
Hence, this is the first paper to introduce inter-agent reward distribution to MARL communications.

Auction theory is discussed in terms of mechanism design \citep{myerson1983mechanism}, also known as inverse game theory.
Second--price auctions \citep{vickrey1961counterspeculation} are auctions including a single product and several buyers. 
In this paper, a digital goods auction \citep{guruswami2005profit} was used as an auction with an infinite supply.
Several methods extend digital goods auction to address collusion, including the consensus estimate \citep{goldberg2003competitiveness} and random sample auction \citep{goldberg2006competitive}, which can be used to improve our method.

This paper is also related to DropConnect in terms of controlling connections between units.
Adaptive DropConnect (ADC), proposed in a later section of this paper as a further application, extends the DropConnect \citep{wan2013regularization} regularization technique.
The finalized idea of ADC (which uses a skew probability correlated to the absolute value of weights rather than dropping each connection between units by a constant probability) is closer to Adaptive DropOut \citep{ba2013adaptive}, although their derivation differs.
The adjective ``adaptive'' is added with respect to the method.
Neural network optimizing using RL was investigated by \cite{andrychowicz2016learning}; however, 
their methods used a recurrent neural network (RNN) and are therefore difficult to implement,
whereas the proposed method is RNN-free and forms as a layer. For these reasons, its implementation is simple and fast and it also has a wide area of applicability.
