\section{Related Work}
現在成功している深層強化学習のモデルの多くは、単一のエージェントが環境の観測から認知、行動決定といった一連のプロセスを担う。
DQN \citep{mnih2015human,silver2016mastering} は、Atari のスクリーン系列から最適な行動を決定したり、AlphaGo のモジュールとして囲碁の盤面から勝利に最も近い一手を選ぶ。
DDPG \citep{lillicrap2015continuous} は物理空間において摩擦や重力係数などの条件を考慮した多関節の制御を実現する。
単一のエージェントを用いて強化学習を解くという試みは、人間の持つ身体性のアナロジーから考えると一見して妥当であるように思えるが、現実世界は open world であり、単一のエージェントが完全に情報が観測することが難しい。
そのためマルチエージェントによるアプローチが求められている。
%A3C \citep{mnih2016asynchronous} 

深層強化学習を POMDP 環境に適用する研究はいくつか行われている。
Deep Recurrent Q-Network (DRQN) \citep{sorokin2015deep} は、
隠れマルコフ連鎖を想定し、リカレントニューラルネットワーク(RNN)を用いて真の状態を推定している。
%他にも、エレベーター制御\citep{crites1998elevator}、センサーネットワーク\citep{fox2000probabilistic}、ロボットサッカー\citep{stone1998towards}などがマルチエージェントによって解かれている（修正中：最新の研究をサーベイ）。

マルチエージェントシステムによる強化学習へのアプローチにはいくつかの方法がある。
一つは、学習の効率を高めるために、同一のモデルに従う複数のエージェントを用いて探索を行う方法であり、Gorilla \citep{nair2015massively} , A3C \citep{mnih2016asynchronous} などで採用されている。
二つ目は、アクチュエーターを増やすことによって行動の量を増やす方法であり、サッカーゲーム \citep{kalyanakrishnan2006half} やテレビゲーム \citep{tampuu2017multiagent} で行われている。
三つ目は、センサーを増やすことによって観測の量を増やす方法であり、自動運転\citep{sukhbaatar2016learning}やセンサーネットワーク\citep{fox2000probabilistic}などで行われている。
本研究は、観測困難な環境からいかに良い状態表現を得るかに注目しているため、三つ目のケースをスコープとする。


マルチエージェントで強化学習の問題を解決する場合には、信頼度割り当て問題の解決が重要になる。
そこで、エージェントの信頼度を、そのエージェントがいた場合と、
いなかったと仮定した場合の差として定量化する研究が行われている。
QUICR-learning \citep{agogino2006quicr} では、エージェント $i$ が reward $R(a_t)$ の代わりに、
そのエージェントがある行動 $a_{it}$ をとった場合 $a_t$ と取らなかった場合 $a_t-a_{ti}$ の差、
counterfactual reward $R(a_t) - R(a_t - a_{it})$ の cumulative discount summation を最大化している。
COMA \citep{foerster2017counterfactual} は、actor-critic において critic が共通しており、actor がマルチエージェントであるという actor-critic の仕組みを考え、それぞれの actor が counterfactual reward を最大化するような仕組みを考えている。

マルチエージェントによる観測および認知の枠組みは、センサー処理の分野ではエッジコンピューティング\citep{bonomi2012fog}としても知られている。
エッジコンピューティングは分散環境を前提とした信号処理のモデルであり、一つの処理系がすべてのデータを処理するのではなく、複数のセンサーの情報を一つのエッジサーバが集約し、複数のエッジサーバが次元削減したデータをデータセンターに送るという階層的な構造をしている。
本研究は、実際に IoT の環境で本研究が適用されるケースを想定している。
報酬はビットコインなどの決済手段によって送金が可能であるため、
Web 全体でスケーラブルなモデルが実現できる可能性がある。

NaaA の設計は、神経科学からヒントを得ている。
神経回路に含まれるニューロンは一つの細胞であるため、エネルギーを消費する。
通常の細胞と同様に酸素や ATP がエネルギー源となり、これらはニューロンと接続した、アストロサイトから供給される。
アストロサイトは脳の構造を支えるグリア細胞の一種であり、血管からニューロンへの栄養供給を行う。
エネルギー量は有限であるため、不要なニューロンはアポトーシスによって死滅する。
アポトーシスは NGF (nerve growth factor), BDNF (brain derived neurofactor) などの神経栄養因子(neurotorophin; NTF)によって制御されるため、より多くの NTF を獲得できたニューロンが生存する。
各神経細胞を独立した生物として捉える見方はニューラルダーウィズム\citep{edelman1987neural}と呼ばれる。

